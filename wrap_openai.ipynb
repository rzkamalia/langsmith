{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "from langsmith import traceable\n",
    "\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "APP_VERSION = os.environ[\"APP_VERSION\"]\n",
    "MODEL_NAME = os.environ[\"MODEL_NAME\"]\n",
    "MODEL_PROVIDER = os.environ[\"MODEL_PROVIDER\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "from langsmith.wrappers import wrap_openai\n",
    "from utils import get_vector_db_retriever\n",
    "\n",
    "\n",
    "RAG_SYSTEM_PROMPT = \"\"\"\n",
    "    You are an assistant for question-answering tasks. \n",
    "    Use the following pieces of retrieved context to answer the latest question in the conversation. \n",
    "    If you don't know the answer, just say that you don't know. \n",
    "    Use three sentences maximum and keep the answer concise.\n",
    "\"\"\"\n",
    "\n",
    "openai_client = wrap_openai(openai.Client())\n",
    "nest_asyncio.apply()\n",
    "retriever = get_vector_db_retriever()\n",
    "\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def retrieve_documents(question: str):\n",
    "    return retriever.invoke(question)\n",
    "\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def generate_response(question: str, documents):\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": RAG_SYSTEM_PROMPT\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Context: {formatted_docs} \\n\\n Question: {question}\"\n",
    "        }\n",
    "    ]\n",
    "    return openai_client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=messages,\n",
    "    )\n",
    "\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def langsmith_rag_with_wrap_openai(question: str):\n",
    "    documents = retrieve_documents(question)\n",
    "    response = generate_response(question, documents)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To trace with `wrap_openai`, first import it using `from langsmith.wrappers import wrap_openai`, then wrap your OpenAI client with `openai_client = wrap_openai(OpenAI())`. Make sure to set the environment variable `LANGSMITH_TRACING` to \\'true\\' to enable logging, and also set your `LANGSMITH_API_KEY`. By default, traces will be logged to a project named \"default,\" but you can log them to a different project if needed.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"How do I trace with wrap_openai?\"\n",
    "ai_answer = langsmith_rag_with_wrap_openai(question)\n",
    "ai_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-BIEHqtm99B5e7cXBVq62y03xXXKJa', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The color of the sky typically appears blue during the day due to the scattering of sunlight by the atmosphere. This phenomenon, known as Rayleigh scattering, causes shorter blue wavelengths of light to scatter more than other colors. At sunrise and sunset, the sky can display a range of colors, including orange, pink, and red, as the light passes through more of the atmosphere. Additionally, the sky can appear gray or even white on overcast days.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, annotations=[]))], created=1743684522, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_b376dfbbd5', usage=CompletionUsage(completion_tokens=91, prompt_tokens=13, total_tokens=104, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the wrapped OpenAI client accepts all the same langsmith_extra parameters as @traceable decorated functions.\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What color is the sky?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "openai_client.chat.completions.create(\n",
    "    model=MODEL_NAME,\n",
    "    messages=messages,\n",
    "    langsmith_extra={\"metadata\": {\"foo\": \"bar\"}},\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
