{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "from langsmith import traceable\n",
    "\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "MODEL_NAME = os.environ[\"MODEL_NAME\"]\n",
    "MODEL_PROVIDER = os.environ[\"MODEL_PROVIDER\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'choices': [{'message': {'role': 'assistant',\n",
       "    'content': 'Sure, what time would you like to book the table for?'}}]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = [\n",
    "\t{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "\t{\"role\": \"user\", \"content\": \"I'd like to book a table for two.\"},\n",
    "]\n",
    "\n",
    "output = {\n",
    "\t\"choices\": [\n",
    "\t\t{\n",
    "\t\t\t\"message\": {\n",
    "\t\t\t\t\"role\": \"assistant\",\n",
    "\t\t\t\t\"content\": \"Sure, what time would you like to book the table for?\"\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t]\n",
    "}\n",
    "\n",
    "@traceable(\n",
    "\trun_type=\"llm\", \n",
    "\tmetadata={\n",
    "\t\t\"model_name\": MODEL_NAME, \n",
    "\t\t\"model_provider\": MODEL_PROVIDER\n",
    "\t}\n",
    ")\n",
    "def chat_model(messages: list):\n",
    "\treturn output\n",
    "\n",
    "chat_model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'choices': [{'message': {'content': 'Hello, polly the parrot',\n",
       "     'role': 'assistant'}}]}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _reduce_chunks(chunks: list):\n",
    "    all_text = \"\".join([chunk[\"choices\"][0][\"message\"][\"content\"] for chunk in chunks])\n",
    "    return {\"choices\": [{\"message\": {\"content\": all_text, \"role\": \"assistant\"}}]}\n",
    "\n",
    "@traceable(\n",
    "    run_type=\"llm\",\n",
    "    metadata={\n",
    "        \"ls_provider\": MODEL_PROVIDER, \n",
    "        \"ls_model_name\": MODEL_NAME\n",
    "    },\n",
    "    reduce_fn=_reduce_chunks\n",
    ")\n",
    "def my_streaming_chat_model(messages: list):\n",
    "    for chunk in [\"Hello, \" + messages[1][\"content\"]]:\n",
    "        yield {\n",
    "            \"choices\": [\n",
    "                {\n",
    "                    \"message\": {\n",
    "                        \"content\": chunk,\n",
    "                        \"role\": \"assistant\",\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "list(\n",
    "    my_streaming_chat_model(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant. Please greet the user.\"},\n",
    "            {\"role\": \"user\", \"content\": \"polly the parrot\"},\n",
    "        ],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_content': 'Document contents 1',\n",
       "  'type': 'Document',\n",
       "  'metadata': {'foo': 'bar'}},\n",
       " {'page_content': 'Document contents 2',\n",
       "  'type': 'Document',\n",
       "  'metadata': {'foo': 'bar'}},\n",
       " {'page_content': 'Document contents 3',\n",
       "  'type': 'Document',\n",
       "  'metadata': {'foo': 'bar'}}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _convert_docs(results):\n",
    "  return [\n",
    "      {\n",
    "          \"page_content\": r,\n",
    "          \"type\": \"Document\",\n",
    "          \"metadata\": {\"foo\": \"bar\"}\n",
    "      }\n",
    "      for r in results\n",
    "  ]\n",
    "\n",
    "@traceable(\n",
    "    run_type=\"retriever\"\n",
    ")\n",
    "def retrieve_docs(query):\n",
    "  \"\"\"Retriever returning hardcoded dummy documents. In production, this could be a real vector datatabase or other document index.\n",
    "  \"\"\"\n",
    "  contents = [\"Document contents 1\", \"Document contents 2\", \"Document contents 3\"]\n",
    "  return _convert_docs(contents)\n",
    "\n",
    "retrieve_docs(\"User query.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-BHlF3yPJHvLGdL28wRc0Nrmv99HQO', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The current temperature in New York City is 65Â°F. If you need more detailed weather information, feel free to ask!', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, annotations=[]))], created=1743572873, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_b376dfbbd5', usage=CompletionUsage(completion_tokens=26, prompt_tokens=83, total_tokens=109, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from openai import OpenAI\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "\n",
    "openai_client = OpenAI()\n",
    "\n",
    "@traceable(\n",
    "  run_type=\"tool\"\n",
    ")\n",
    "def get_current_temperature(location: str, unit: str):\n",
    "    return 65 if unit == \"Fahrenheit\" else 17\n",
    "\n",
    "\n",
    "@traceable(run_type=\"llm\")\n",
    "def call_openai(\n",
    "    messages: List[Dict], tools: Optional[List[Dict]]\n",
    ") -> str:\n",
    "\treturn openai_client.chat.completions.create(\n",
    "\t\tmodel=MODEL_NAME,\n",
    "\t\tmessages=messages,\n",
    "\t\ttemperature=0,\n",
    "\t\ttools=tools\n",
    "\t)\n",
    "\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def ask_about_the_weather(inputs, tools):\n",
    "\tresponse = call_openai(inputs, tools)\n",
    "\ttool_call_args = json.loads(response.choices[0].message.tool_calls[0].function.arguments)\n",
    "\tlocation = tool_call_args[\"location\"]\n",
    "\tunit = tool_call_args[\"unit\"]\n",
    "\ttool_response_message = {\n",
    "\t\t\"role\": \"tool\",\n",
    "\t\t\"content\": json.dumps(\n",
    "\t\t\t{\n",
    "\t\t\t\t\"location\": location,\n",
    "\t\t\t\t\"unit\": unit,\n",
    "\t\t\t\t\"temperature\": get_current_temperature(location, unit),\n",
    "\t\t\t}\n",
    "\t\t),\n",
    "\t\t\"tool_call_id\": response.choices[0].message.tool_calls[0].id\n",
    "\t}\n",
    "\tinputs.append(response.choices[0].message)\n",
    "\tinputs.append(tool_response_message)\n",
    "\toutput = call_openai(inputs, None)\n",
    "\treturn output\n",
    "\n",
    "\n",
    "tools = [\n",
    "\t{\n",
    "\t\t\"type\": \"function\",\n",
    "\t\t\"function\": {\n",
    "\t\t\t\"name\": \"get_current_temperature\",\n",
    "\t\t\t\"description\": \"Get the current temperature for a specific location\",\n",
    "\t\t\t\"parameters\": {\n",
    "\t\t\t\t\"type\": \"object\",\n",
    "\t\t\t\t\"properties\": {\n",
    "\t\t\t\t\t\"location\": {\n",
    "\t\t\t\t\t\t\"type\": \"string\",\n",
    "\t\t\t\t\t\t\"description\": \"The city and state, e.g., San Francisco, CA\"\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t\t\"unit\": {\n",
    "\t\t\t\t\t\t\"type\": \"string\",\n",
    "\t\t\t\t\t\t\"enum\": [\"Celsius\", \"Fahrenheit\"],\n",
    "\t\t\t\t\t\t\"description\": \"The temperature unit to use. Infer this from the user's location.\"\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t},\n",
    "\t\t\t\t\"required\": [\"location\", \"unit\"]\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t}\n",
    "]\n",
    "inputs = [\n",
    "  {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "  {\"role\": \"user\", \"content\": \"What is the weather today in New York City?\"},\n",
    "]\n",
    "\n",
    "ask_about_the_weather(inputs, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
