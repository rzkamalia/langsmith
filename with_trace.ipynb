{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "from langsmith import trace, traceable\n",
    "\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "MODEL_NAME = os.environ[\"MODEL_NAME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "Fetching pages:  72%|#######2  | 171/236 [00:31<00:10,  5.98it/s]Error fetching https://docs.smith.langchain.com/pricing, skipping due to continue_on_failure=True\n",
      "Fetching pages: 100%|##########| 236/236 [00:43<00:00,  5.38it/s]\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "from openai import OpenAI\n",
    "from typing import Dict, List\n",
    "from utils import get_vector_db_retriever\n",
    "\n",
    "\n",
    "RAG_SYSTEM_PROMPT = \"\"\"\n",
    "\tYou are an assistant for question-answering tasks. \n",
    "\tUse the following pieces of retrieved context to answer the latest question in the conversation. \n",
    "\tIf you don't know the answer, just say that you don't know. \n",
    "\tUse three sentences maximum and keep the answer concise.\n",
    "\"\"\"\n",
    "\n",
    "openai_client = OpenAI()\n",
    "nest_asyncio.apply()\n",
    "retriever = get_vector_db_retriever()\n",
    "\n",
    "\n",
    "@traceable\n",
    "def retrieve_documents(question: str):\n",
    "    documents = retriever.invoke(question)\n",
    "    return documents\n",
    "\n",
    "\n",
    "def generate_response(question: str, documents):\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\t    # note: our documents came in as a list of objects, but we just want to log a string.\n",
    "    with trace(\n",
    "    name=\"Generate Response\",\n",
    "    run_type=\"chain\",\n",
    "    inputs={\n",
    "        \"question\": question, \n",
    "        \"formatted_docs\": formatted_docs\n",
    "    },\n",
    "    metadata={\"foo\": \"bar\"},\n",
    "    ) as ls_trace:\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": RAG_SYSTEM_PROMPT\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Context: {formatted_docs} \\n\\n Question: {question}\"\n",
    "            }\n",
    "        ]\n",
    "        response = call_openai(messages)\n",
    "        ls_trace.end(outputs={\"output\": response})\n",
    "    return response\n",
    "\n",
    "\n",
    "@traceable\n",
    "def call_openai(messages: List[Dict], model: str = MODEL_NAME, temperature: float = 0.0) -> str:\n",
    "    response = openai_client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    temperature=temperature,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "@traceable\n",
    "def langsmith_rag(question: str):\n",
    "    documents = retrieve_documents(question)\n",
    "    response = generate_response(question, documents)\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To trace with the tracing context manager in Python, you can use it to log traces for a specific block of code by wrapping that code within the context manager. This allows you to control the inputs, outputs, and other attributes of the trace. It's particularly useful when using a decorator or wrapper is not feasible.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"How do I trace with tracing context?\"\n",
    "ai_answer = langsmith_rag(question)\n",
    "ai_answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
